= Apache Kafka.
v1.0, 2020-11-10
:example-caption!:
:sectnums:
:sectnumlevels: 10

== Kafka

=== Event-driven architecture:
- Microservices
- Serverless
- FaaS
- Streaming
- Event Sourcing
- CQRS



== Apache Kafka on windows
=== Install
link:https://www.apache.org/dyn/closer.cgi?path=/kafka/2.6.0/kafka_2.13-2.6.0.tgz[Downlaod]
[source]
----
tar -xzf kafka_2.13-2.6.0.tgz
cd kafka_2.13-2.6.0
----
=== Run
[source]
----
D:\kafka_2.13-2.6.0\bin\windows\zookeeper-server-start.bat D:\kafka_2.13-2.6.0\config\zookeeper.properties
D:\kafka_2.13-2.6.0\bin\windows\kafka-server-start.bat D:\kafka_2.13-2.6.0\config\server.properties

D:\kafka_2.13-2.6.0\bin\windows\zookeeper-server-start.bat D:\kafka_2.13-2.6.0\config\zookeeper.properties

xcopy D:\kafka_2.13-2.6.0\config\server.properties D:\kafka_2.13-2.6.0\config\server-1.properties
xcopy D:\kafka_2.13-2.6.0\config\server.properties D:\kafka_2.13-2.6.0\config\server-2.properties

D:\kafka_2.13-2.6.0\bin\windows\kafka-server-start.bat D:\kafka_2.13-2.6.0\config\server-1.properties
D:\kafka_2.13-2.6.0\bin\windows\kafka-server-start.bat D:\kafka_2.13-2.6.0\config\server-2.properties
----
=== Kafka Tool
link:https://www.kafkatool.com/download.html[Kafka Tool]

== Topics
[source]
----
D:\kafka_2.13-2.6.0\bin\windows\kafka-topics.bat --create --bootstrap-server localhost:9093 --partitions 2 --replication-factor 2 --topic user-tracking

D:\kafka_2.13-2.6.0\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9093 user-tracking
----

== Avro
++++
<iframe width="560" height="315" src="https://www.youtube.com/watch?v=_6HTHH1NCK0&list=PLsC0nE-wJ1I6uYSZomY4-WWeOuLeDEDAK&index=2" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
++++
https://github.com/simplesteph/kafka-avro-course

=== Compile Avro schema

https://apache.mirror.serveriai.lt/avro/avro-1.10.0/java/avro-tools-1.10.0.jar[Download Avro]
[source]
----
set JAVA_HOME=%ProgramFiles%\Java\jdk1.7.0_79

cd D:\JAVA_PROJECTS\apache-kafka\src\main\java\schemas

java -jar D:\avro-tools-1.10.0.jar compile schema user_schema.avsc .
"%ProgramFiles%\Java\jdk1.8.0_25\bin\java" -jar D:\avro-tools-1.10.0.jar compile schema user_schema.avsc .
----
=== Schema Registry
==== Simpliest schema registry
link:https://medium.com/@shreeraman.ak/spark-kafka-and-schema-registry-part-2-af9e6c054125[simpliest schema registry]
[source]
----
git clone https://github.com/Landoop/schema-registry-ui.git
cd schema-registry-ui
npm install
npm start
http://localhost:8080
----
==== Schema registry with docker-compose
https://github.com/lensesio/fast-data-dev
++++
<iframe width="560" height="315" src="https://www.youtube.com/watch?v=O8T7AUxhoKo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
++++
[source]
----
https://github.com/ackintosh/kafka-connect-colormeshop/blob/master/docker-compose.yml

wget https://raw.githubusercontent.com/ackintosh/kafka-connect-colormeshop/master/docker-compose.yml

docker-compose up kafka-cluster

http://192.168.56.10:3030/
----
===== Create topic in schema registry

 https://youtu.be/O8T7AUxhoKo?t=359
 docker run --rm -it --net=host landoop/fast-data-dev bash

 kafka-topics --create --topic demo-kafka-connect --partitions 3 --replication-factor 1 --zookeeper 127.0.0.1:2181

==== Create file connector in schema registry
[source]
----
name=file-stream-demo-distributed
connector.class=org.apache.kafka.connect.file.FileStreamSourceConnector
tasks.max=1
file=demo-file.txt
topic=demo-kafka-connect
key.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=true
----
[source]
----
http://192.168.56.10:3030/kafka-topics-ui/#/cluster/fast-data-dev/topic/n/demo-kafka-connect/

docker ps
docker exec -it <containerID> bash
touch demo-file.txt
echo "hi" >> demo-file.txt
echo "ho" >> demo-file.txt
echo "hu" >> demo-file.txt
----



sudo yum install git -y
sudo yum install java-11-openjdk-devel -y
sudo yum install maven -y
git clone https://github.com/confluentinc/schema-registry
cd schema-registry]
git checkout v5.2.0
mvn package

[source]
----
wget https://raw.githubusercontent.com/obsidiandynamics/kafdrop/master/docker-compose/kafka-kafdrop/docker-compose.yaml
docker-compose up
http://192.168.56.10:9000
----


== Streaming

=== Froud detection system
[plantuml, diagram-classes, png]
....
@startuml
title Froud detection system
|UI|
start
:User \nMakes\nan order;
|Backend|
if (userId is present?) then (no)
    |UI|
    :No userId<
    stop
else (yes)
    |Backend|
    if ( # of items < 1000?) then (no)
        |UI|
        : # of items >= 1000<
        stop
    else (yes)
        |Backend|
    endif
    |Backend|
    if (amount < $10000?) then (no)
        |UI|
        : amount >= $10000<
        stop
    else (yes)
        |UI|
        : OK<
        stop
    endif

endif
@enduml
....
==== Traditional Design
[plantuml, Payment-Service, png]
....
@startuml
title Payment Service
|Validation|
    start
    :$;
|Fround Detection|
    if ($) then (no)
        |Data Base|
        :persist KO;
        |Validation|
        :bad $<
        stop
    else (yes)
        |Data Base|
        :persist OK;
        |Processing|
        stop
    endif
@enduml
....



==== Streaming with Kafka

[plantuml, Test, png]
....
partition PaymentService {
    (*) --> "$ $ $"
}
partition KafkaCluster {

    --> "payments"
}
partition FraudDetection {
    --> "Consumer"

    partition BusinessRules {
        --> " #1"
        --> " #2"
        --> " #..."
    }
    note right: All rules\nmust be valid
}
partition FraudDetection  {
    --> "Producer"
}
partition KafkaCluster {
    --> "validated payments"
}
partition PaymentProcessor {
--> "OK"
}
....
==== Kafka Streams
[plantuml, Kafka Streams, png]
....
partition TopicA {
    start
}
partition KafkaStream {
        - Consumer

        partition topology {
            note right: * topology=\nacyclic graph of sources,\nprocessors and sinks
            - Filter
            - Map
            - Count
            - StateStore
            - Count
        }
        - Producer
}
partition TopicB {
    stop
}
....
==== Stream Topology
[plantuml, Stream Topology, png]
....
|Consumer(Source)|
start
:Consumer;
|Stream Processors|
    :Filter;
    :Map;
    :Count;
    :StateStore;
    :Count;
    :...;
|Producer(Sink)|
    :Producer;
....
==== Stateless Operations

link:https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#stateless-transformations[Stateless Transformations @*kafka.apache.org*]

- Branch
- Filter
- Inverse Filter
- Map
- FlatMap
- Foreach
- Peek
- GroupBy
- Merge

==== Stateful Operations

link:https://kafka.apache.org/documentation/streams/developer-guide/dsl-api.html#stateful-transformations[Stateful Transformations @*kafka.apache.org*]


- Aggregation
- Count
- Joins
- Windowing
- Custom processors
